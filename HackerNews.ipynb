{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "01bd76ab9782c73646930a8c6ac495eb93d52786"
   },
   "source": [
    "# Hacker News Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here show picture of the inital code. Simple and pretty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then tell story of how it was beautiful but couldnt last. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Google BigQuery querys... 3.2gb... yikes! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "#!pip install google-cloud-bigquery\n",
    "#!pip install textblob\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from textblob import TextBlob\n",
    "import bokeh\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import html \n",
    "import dask\n",
    "import re\n",
    "import dask.dataframe as dd\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "\n",
    "# Define the BigQuery Client\n",
    "client = bigquery.Client.from_service_account_json(\"winterrose-nlp-49041459bd3c.json\")\n",
    "\n",
    "# A Google BigQuery Function\n",
    "def querytodf(query):\n",
    "    query_job = client.query(query)\n",
    "    \n",
    "    iterator = query_job.result(timeout=60)\n",
    "    rows = list(iterator)\n",
    "\n",
    "    # Transform the rows into a nice pandas dataframe\n",
    "    df = pd.DataFrame(data=[list(x.values()) for x in rows], columns=list(rows[0].keys()))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit query to Google BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 3s, sys: 11.4 s, total: 3min 15s\n",
      "Wall time: 12min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Using WHERE reduces the amount of data scanned / quota used\n",
    "query = \"\"\"\n",
    "SELECT hnc.id, \n",
    "       hnc.by,\n",
    "       hnc.author,\n",
    "       hnc.text, \n",
    "       hnc.time, \n",
    "       hnc.ranking, \n",
    "       hnc.deleted, \n",
    "       hnc.dead, \n",
    "       hnc.parent as sid,\n",
    "       hns.by as sauthor,\n",
    "       hns.time as stime,\n",
    "       hns.title as stitle,\n",
    "       hns.deleted as sdeleted,\n",
    "       hns.dead as sdead,\n",
    "       hns.score as score,\n",
    "       hns.text as stext,\n",
    "       hns.url as surl\n",
    "FROM `bigquery-public-data.hacker_news.comments` as hnc\n",
    "INNER JOIN `bigquery-public-data.hacker_news.stories`as hns ON hns.id  = hnc.parent\n",
    "\"\"\"\n",
    "df = querytodf(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect shape of completed query. Verify that all rows are present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "b88e551ef1d6c2562e1beff9d60be3c88e83ce02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2620593, 17)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "a6d7b7611d8aa093224b66ec3131a8586cc71b20"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>by</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>ranking</th>\n",
       "      <th>deleted</th>\n",
       "      <th>dead</th>\n",
       "      <th>sid</th>\n",
       "      <th>sauthor</th>\n",
       "      <th>stime</th>\n",
       "      <th>stitle</th>\n",
       "      <th>sdeleted</th>\n",
       "      <th>sdead</th>\n",
       "      <th>score</th>\n",
       "      <th>stext</th>\n",
       "      <th>surl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1935438</td>\n",
       "      <td>tocomment</td>\n",
       "      <td>tocomment</td>\n",
       "      <td>What should I take away from this?</td>\n",
       "      <td>1290547754</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1935059</td>\n",
       "      <td>atularora</td>\n",
       "      <td>1290541321</td>\n",
       "      <td>What Android is</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>212.0</td>\n",
       "      <td></td>\n",
       "      <td>http://www.tbray.org/ongoing/When/201x/2010/11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102967</td>\n",
       "      <td>wallflower</td>\n",
       "      <td>wallflower</td>\n",
       "      <td>I see a trend that indicates flattening of rev...</td>\n",
       "      <td>1201116956</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>102843</td>\n",
       "      <td>kirubakaran</td>\n",
       "      <td>1201104980</td>\n",
       "      <td>Apple stock plunges $30. Sky IS falling.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>25.0</td>\n",
       "      <td></td>\n",
       "      <td>http://finance.google.com/finance?q=AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8165541</td>\n",
       "      <td>sobkas</td>\n",
       "      <td>sobkas</td>\n",
       "      <td>This remainds me of sd card hacking:\\n&lt;a href=...</td>\n",
       "      <td>1407794353</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8164766</td>\n",
       "      <td>thefreeman</td>\n",
       "      <td>1407784981</td>\n",
       "      <td>BadUSB â€“ On accessories that turn evil [pdf]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>84.0</td>\n",
       "      <td></td>\n",
       "      <td>https://srlabs.de/blog/wp-content/uploads/2014...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10373528</td>\n",
       "      <td>glormph</td>\n",
       "      <td>glormph</td>\n",
       "      <td>Someone mentioned that FB may want to be the w...</td>\n",
       "      <td>1444644248</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10372964</td>\n",
       "      <td>aestetix</td>\n",
       "      <td>1444633632</td>\n",
       "      <td>Global coalition tells Facebook to kill its Re...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>78.0</td>\n",
       "      <td>None</td>\n",
       "      <td>https://boingboing.net/2015/10/06/global-coali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4209452</td>\n",
       "      <td>vamsikv</td>\n",
       "      <td>vamsikv</td>\n",
       "      <td>....</td>\n",
       "      <td>1341606025</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4209294</td>\n",
       "      <td>diminium</td>\n",
       "      <td>1341603367</td>\n",
       "      <td>Ask HN: App Store Devs, Are you guys still mot...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>9.0</td>\n",
       "      <td>We now know that the vast majority of apps mak...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id          by      author  \\\n",
       "0   1935438   tocomment   tocomment   \n",
       "1    102967  wallflower  wallflower   \n",
       "2   8165541      sobkas      sobkas   \n",
       "3  10373528     glormph     glormph   \n",
       "4   4209452     vamsikv     vamsikv   \n",
       "\n",
       "                                                text        time  ranking  \\\n",
       "0                 What should I take away from this?  1290547754        5   \n",
       "1  I see a trend that indicates flattening of rev...  1201116956        5   \n",
       "2  This remainds me of sd card hacking:\\n<a href=...  1407794353        6   \n",
       "3  Someone mentioned that FB may want to be the w...  1444644248        6   \n",
       "4                                               ....  1341606025        7   \n",
       "\n",
       "  deleted  dead       sid      sauthor       stime  \\\n",
       "0    None  None   1935059    atularora  1290541321   \n",
       "1    None  None    102843  kirubakaran  1201104980   \n",
       "2    None  None   8164766   thefreeman  1407784981   \n",
       "3    None  None  10372964     aestetix  1444633632   \n",
       "4    None  None   4209294     diminium  1341603367   \n",
       "\n",
       "                                              stitle sdeleted sdead  score  \\\n",
       "0                                    What Android is     None  None  212.0   \n",
       "1           Apple stock plunges $30. Sky IS falling.     None  None   25.0   \n",
       "2       BadUSB â€“ On accessories that turn evil [pdf]     None  None   84.0   \n",
       "3  Global coalition tells Facebook to kill its Re...     None  None   78.0   \n",
       "4  Ask HN: App Store Devs, Are you guys still mot...     None  None    9.0   \n",
       "\n",
       "                                               stext  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                               None   \n",
       "4  We now know that the vast majority of apps mak...   \n",
       "\n",
       "                                                surl  \n",
       "0  http://www.tbray.org/ongoing/When/201x/2010/11...  \n",
       "1           http://finance.google.com/finance?q=AAPL  \n",
       "2  https://srlabs.de/blog/wp-content/uploads/2014...  \n",
       "3  https://boingboing.net/2015/10/06/global-coali...  \n",
       "4                                                     "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save query results to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.3 s, sys: 1.62 s, total: 57.9 s\n",
      "Wall time: 58.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.to_csv('data/hn_commentors_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV back into new Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22 s, sys: 1.64 s, total: 23.6 s\n",
      "Wall time: 23.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds2 = pd.read_csv('data/hn_commentors_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect and verify that all rows are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2620593, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>by</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>ranking</th>\n",
       "      <th>deleted</th>\n",
       "      <th>dead</th>\n",
       "      <th>sid</th>\n",
       "      <th>sauthor</th>\n",
       "      <th>stime</th>\n",
       "      <th>stitle</th>\n",
       "      <th>sdeleted</th>\n",
       "      <th>sdead</th>\n",
       "      <th>score</th>\n",
       "      <th>stext</th>\n",
       "      <th>surl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1935438</td>\n",
       "      <td>tocomment</td>\n",
       "      <td>tocomment</td>\n",
       "      <td>What should I take away from this?</td>\n",
       "      <td>1290547754</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1935059</td>\n",
       "      <td>atularora</td>\n",
       "      <td>1290541321</td>\n",
       "      <td>What Android is</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>212.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.tbray.org/ongoing/When/201x/2010/11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>102967</td>\n",
       "      <td>wallflower</td>\n",
       "      <td>wallflower</td>\n",
       "      <td>I see a trend that indicates flattening of rev...</td>\n",
       "      <td>1201116956</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102843</td>\n",
       "      <td>kirubakaran</td>\n",
       "      <td>1201104980</td>\n",
       "      <td>Apple stock plunges $30. Sky IS falling.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://finance.google.com/finance?q=AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8165541</td>\n",
       "      <td>sobkas</td>\n",
       "      <td>sobkas</td>\n",
       "      <td>This remainds me of sd card hacking:\\n&lt;a href=...</td>\n",
       "      <td>1407794353</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8164766</td>\n",
       "      <td>thefreeman</td>\n",
       "      <td>1407784981</td>\n",
       "      <td>BadUSB â€“ On accessories that turn evil [pdf]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://srlabs.de/blog/wp-content/uploads/2014...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id          by      author  \\\n",
       "0           0  1935438   tocomment   tocomment   \n",
       "1           1   102967  wallflower  wallflower   \n",
       "2           2  8165541      sobkas      sobkas   \n",
       "\n",
       "                                                text        time  ranking  \\\n",
       "0                 What should I take away from this?  1290547754        5   \n",
       "1  I see a trend that indicates flattening of rev...  1201116956        5   \n",
       "2  This remainds me of sd card hacking:\\n<a href=...  1407794353        6   \n",
       "\n",
       "  deleted dead      sid      sauthor       stime  \\\n",
       "0     NaN  NaN  1935059    atularora  1290541321   \n",
       "1     NaN  NaN   102843  kirubakaran  1201104980   \n",
       "2     NaN  NaN  8164766   thefreeman  1407784981   \n",
       "\n",
       "                                         stitle sdeleted sdead  score stext  \\\n",
       "0                               What Android is      NaN   NaN  212.0   NaN   \n",
       "1      Apple stock plunges $30. Sky IS falling.      NaN   NaN   25.0   NaN   \n",
       "2  BadUSB â€“ On accessories that turn evil [pdf]      NaN   NaN   84.0   NaN   \n",
       "\n",
       "                                                surl  \n",
       "0  http://www.tbray.org/ongoing/When/201x/2010/11...  \n",
       "1           http://finance.google.com/finance?q=AAPL  \n",
       "2  https://srlabs.de/blog/wp-content/uploads/2014...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(ds2.shape)\n",
    "display(ds2.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all  `author` and `text` NaN rows from Dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This many nans: 80486\n",
      "New Shape after nan removal: (2540107, 18)\n"
     ]
    }
   ],
   "source": [
    "nans = ds2.text.isna().sum()\n",
    "print('This many nans:', nans)\n",
    "ds2 = ds2.dropna(subset=['author', 'text'])\n",
    "print('New Shape after nan removal:', ds2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis and Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "800fd0be97d8d4111ebcb7c6d5968cc944bc08b7"
   },
   "outputs": [],
   "source": [
    "def encode_decode(text):\n",
    "    \"\"\"\n",
    "    Utility function to clean text by decoding HTML text.\n",
    "    \"\"\"\n",
    "    unescaped = html.unescape(text)\n",
    "    return unescaped\n",
    "\n",
    "def noHTML(text):\n",
    "    \"\"\"\n",
    "    Utility function to clean text by removing HTML flags.\n",
    "    \"\"\"\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', text)\n",
    "    return cleantext\n",
    "\n",
    "def noURLS(text):\n",
    "    \"\"\"\n",
    "    Utility function to clean text by removing links\n",
    "    using simple regex statements.\n",
    "    \"\"\"\n",
    "    return ''.join(re.sub(r\"http\\S+\", \"\", text))\n",
    "\n",
    "def get_sentiment(text):\n",
    "    \"\"\"\n",
    "    Utility function to classify sentiment of passed text\n",
    "    using textblob's sentiment method. Return the polarity\n",
    "    score as a float within the range [-1.0, 1.0]\n",
    "    \"\"\"\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply text cleaning to comment texts and create new column in Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'progress_apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-91706124a5c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# First via Pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mds2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_comment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnoURLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'progress_apply'"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(tqdm())\n",
    "ds2['cleaned_comment'] = ds2.text.progress_apply(lambda x: noURLS(noHTML(encode_decode(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply sentiment analysis (TextBlob.polarity) to each cleaned Comment text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2['comment_sentiment'] = ds2['cleaned_comment'].apply(lambda x: get_sentiment(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove `Unnamed: 0` Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds3 = ds2.loc[:, ~ds2.columns.str.match('Unnamed')]\n",
    "ds3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds3.to_csv('data/hn_all_w_sentiment_cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cleaned / analyzed data back into dataframe from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# IMPORT FROM CSV's\n",
    "ds4 = pd.read_csv('data/hn_all_w_sentiment_cleaned.csv')\n",
    "print(ds4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds4 = d4.loc[:, ~d4.columns.str.match('Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentorList = ds4.by.unique().tolist()\n",
    "print(\"There are this many unique commentors:\", len(commentorList))\n",
    "c_list = pd.DataFrame(commentorList)\n",
    "c_list.columns = ['commentor']\n",
    "display(c_list.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate commentors' sentiment statistics and make final dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define aggreation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loopSentimentAggegator(i):  \n",
    "    \"\"\"\n",
    "    Utility function that groups commment rows by \n",
    "    commentor and returns sentiment statistics and samples\n",
    "    \"\"\"\n",
    "    # Select subdf for the selected author\n",
    "    subdf = ds3[ds3['by'].values == i]\n",
    "    # Commentor Name\n",
    "    commentor = i\n",
    "    # Create a float indicating commentor's mean sentiment score\n",
    "    commentor_sentiment = subdf['comment_sentiment'].mean() \n",
    "    # Upvotes Mean\n",
    "    commentor_upvotes_mean = subdf['ranking'].mean() \n",
    "    # Upvotes Total\n",
    "    commentor_upvotes_total = subdf['ranking'].sum()\n",
    "    # Total Happiness\n",
    "    commentor_total_happyness = subdf[subdf['comment_sentiment'] > 0.0].comment_sentiment.sum() \n",
    "    # Total Saltiness\n",
    "    commentor_total_saltiness = subdf[subdf['comment_sentiment'] < 0.0].comment_sentiment.sum() \n",
    "    # Third output, total number of commments\n",
    "    total_comments = len(subdf.index)\n",
    "    # Total salty comments\n",
    "    qty_salty_comments = (subdf.comment_sentiment < 0.0).sum()\n",
    "    # Total non-salty comments\n",
    "    qty_non_salty_comments = (subdf.comment_sentiment > 0.0).sum()\n",
    "    # Create the second output, a list of the commentor's saltiest comments. \n",
    "    salty_comments = subdf[['time','comment_sentiment','ranking','cleaned_comment', 'stitle']][0:9].to_json(orient='records')\n",
    "    # Ten most positive comments\n",
    "    sweet_comments = subdf[['time','comment_sentiment','ranking','cleaned_comment', 'stitle']].tail(10).to_json(orient='records')\n",
    "    outputDF = pd.DataFrame([{ 'commentor': commentor, \n",
    "                                            'commentor_sentiment': commentor_sentiment, \n",
    "                                            'commentor_upvotes_mean': commentor_upvotes_mean,\n",
    "                                            'commentor_upvotes_total': commentor_upvotes_total,\n",
    "                                            'commentor_total_happyness': commentor_total_happyness,\n",
    "                                            'commentor_total_saltiness': commentor_total_saltiness,\n",
    "                                            'total_comments': total_comments,\n",
    "                                            'qty_salty_comments': qty_salty_comments, \n",
    "                                            'qty_non_salty_comments': qty_non_salty_comments,\n",
    "                                            'salty_comments': salty_comments, \n",
    "                                            'sweet_comments': sweet_comments} ])\n",
    "    return outputDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test function with single commentor to ensure output is good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingDF = loopSentimentAggegator('eli')\n",
    "display(testingDF.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply aggregation functions by commentor to entire dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for j in tqdm(commentorList):\n",
    "    newDF = loopSentimentAggegator(j)\n",
    "    results.append(newDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate aggregation outputs (list of dfs) into a single final dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalTableResults = pd.concat(results)\n",
    "print(finalTableResults.shape)\n",
    "display(finalTableResults.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save final results to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalTableResults.to_csv('data/hn_commentor_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save final results to AVRO (just to be safe) :). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdx.to_avro('data/hn_commentor_data.avro', finalTableResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check lengths & tail to make sure it looks right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvsaved = df.read_csv('data/hn_commentor_data.csv')\n",
    "avrosaved = pdx.read_avro('data/hn_commentor_data.avro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Saved csv shape:', csvsaved.shape)\n",
    "print('Saved avro shape:', avrosaved.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(avrosaved.tail(3))\n",
    "display(csvsaved.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUCCESS!  Now just need to get it into a AWS RDS PostgreSQL instance. : )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Material: The Graveyard - Ideas that didn't work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This didn't work because df.to_sql() is sloooooooow. Just send the CSV straight to PostgreSQL. \n",
    "\n",
    "``` python\n",
    "def verify_output(pgres_engine, table_name):\n",
    "    # ______  verify output-table contents ____\n",
    "    query = 'SELECT * FROM ' + table_name + ' LIMIT 10;'\n",
    "    for row in pgres_engine.execute(query).fetchall():\n",
    "        print(row)\n",
    "    return\n",
    "\n",
    "def run_conversion(pgres_engine):\n",
    "    # ___ process tables ____\n",
    "    df = pdx.read_avro('data/hn_commentors_db.avro')\n",
    "    schema_name = 'lambdaRPG'\n",
    "    tables = ['commentor_data']\n",
    "    df.to_sql(table_name,\n",
    "              if_exists='replace',\n",
    "              con=pgres_engine,\n",
    "              schema=schema_name,\n",
    "              chunksize=10)\n",
    "    verify_output(pgres_engine, table_name)\n",
    "    return\n",
    "\n",
    "def runARVOtoSQL():\n",
    "    # __ Connect to postgres (SQLalchemy.engine) ____\n",
    "    dbname = ''\n",
    "    user = ''\n",
    "    host = ''\n",
    "    password = ''\n",
    "    file = open('aws.pwd', 'r')\n",
    "    ctr = 1\n",
    "    for line in file:\n",
    "        line = line.replace('\\n', '')\n",
    "        if ctr == 1: dbname = line\n",
    "        if ctr == 2: user = line\n",
    "        if ctr == 3: host = line\n",
    "        if ctr == 4: passw = line\n",
    "        ctr = ctr + 1\n",
    "    pgres_str = 'postgresql+psycopg2://'+user+':'+passw+'@'+host+'/'+dbname\n",
    "    pgres_engine = create_engine(pgres_str)\n",
    "    run_conversion(pgres_engine)\n",
    "    print('Conversion successful.....')\n",
    "    return\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "* This didn't work because I need to learn more dask. \n",
    "``` python\n",
    "ds3['comment_sentiment_dask'] = ds3['cleaned_comment'].apply(lambda x: get_sentiment(x)).compute(scheduler='threads')```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This also didn't work. Same reason.\n",
    "``` python\n",
    "dsr3 = ds2\n",
    "dsr3['cleaned_comment'] = dsr3.text.apply(lambda x: noURLS(noHTML(encode_decode(x)))).compute()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This dask layout worked for a few parts but didn't want to thread. And it kept failing because of a deep error. \n",
    "\n",
    "``` python\n",
    "dsr3 = dd.from_pandas(ds2, npartitions=2000)\n",
    "\n",
    "finalDF = dsr2\n",
    "def fin (daskDataframe):\n",
    "    daskDataframe['comment_sentiment'] = daskDataframe.text.apply(lambda x: get_sentiment(noURLS(noHTML(encode_decode(x)))))\n",
    "    daskDataframe['cleaned_comment'] = daskDataframe.text.apply(lambda x: noURLS(noHTML(encode_decode(x))))\n",
    "    return finalDF\n",
    "\n",
    "with ProgressBar():\n",
    "    res = fin(dsr2).compute()``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is helpful. \n",
    "\n",
    "``` console\n",
    "Where to find the dask distributed Bokeh dashboard on aws. \n",
    "\n",
    "URL of accessing Dask Dashboard will be:\n",
    "https://myinstance.notebook.us-east-1.sagemaker.aws/proxy/8787/```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thanks for reading! \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
